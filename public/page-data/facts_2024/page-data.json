{"componentChunkName":"component---src-templates-blog-post-js","path":"/facts_2024/","result":{"data":{"markdownRemark":{"id":"0c955db5-49a8-545d-afa7-bbd353534970","excerpt":"2024 год начался для меня с замечательного подарка от Деда Мороза — видеокарты AMD Radeon RX 7900 XTX. Этот неожиданный сюрприз стал отправной точкой моего…","html":"<p>2024 год начался для меня с замечательного подарка от Деда Мороза — видеокарты AMD Radeon RX 7900 XTX. Этот неожиданный сюрприз стал отправной точкой моего увлекательного пути в мире искусственного интеллекта.</p>\n<p>Видеокарта прибыла в конце января, и на её установку ушло два дня, поскольку для её работы требовался блок питания мощностью 1000 Вт. Когда всё было готово, я с головой погрузился в исследования.</p>\n<p>К сожалению, драйверы от AMD оказались не совсем подходящими для использования в Docker-контейнерах. Но моя цель как DevOps-разработчика оставалась прежней — я продолжал изучать возможности контейнеризации. Спустя два месяца мне наконец удалось запустить свой первый базовый контейнер — <a href=\"https://github.com/HardAndHeavy/transformers-rocm-docker\">transformers-rocm-docker</a>. Это было значимое событие, так как <a href=\"https://github.com/ROCm/ROCm-docker\">оригинальный контейнер от AMD</a> не поддерживал Python 3.11 и выше, а для современных проектов это была минимальная версия для начала работы.</p>\n<p>Первым проектом, который я освоил, стал <a href=\"https://github.com/zylon-ai/private-gpt\">PrivateGPT</a>. Месяц ушёл на изучение Ollama и её моделей GGUF. Параллельно я разбирал проект <a href=\"https://github.com/abetlen/llama-cpp-python\">llama-cpp-python</a>. В результате я создал второй базовый проект <a href=\"https://github.com/HardAndHeavy/llama-rocm-docker\">llama-rocm-docker</a> и сделал свой первый вклад в открытый проект PrivateGPT. В PrivateGPT я <a href=\"https://github.com/zylon-ai/private-gpt/commit/8a836e4651543f099c59e2bf497ab8c55a7cd2e5\">добавил инструкцию для запуска проекта на видеокартах от AMD</a>. А затем написал об этом свою <a href=\"https://habr.com/ru/articles/807469/\">первую статью на Хабре</a>. Она пролежала в песочнице неделю, после чего я стал захабренным, т. е. проверенным автором сообщества.</p>\n<p>Построив прочный фундамент, я приступил к генерации изображений на основе ИИ. Освоил популярный <a href=\"https://github.com/HardAndHeavy/stable-diffusion-webui-rocm-docker\">Stable Diffusion</a> и написал об этом <a href=\"https://habr.com/ru/articles/821967/\">статью</a>. Разобрался с <a href=\"https://github.com/HardAndHeavy/comfyui-rocm-docker\">ComfyUI</a> и <a href=\"https://habr.com/ru/articles/828576/\">научился создавать видео</a>. В своих статьях я старался донести идею использования только контейнеризации для максимальной автоматизации. Идеальный запуск любого проекта для меня — это всего лишь три строки в командной оболочке.</p>\n<p>Драйверы от AMD постоянно совершенствовались, и я поддерживал самые свежие версии. Это дало мне возможность работать с самыми новыми проектами в области ИИ. Например, <a href=\"https://github.com/hiyouga/LLaMA-Factory/commit/c8e18a669adc775f17555cbf06a5ceef6c0d6235\">я внёс поддержку видеокарт AMD</a> в топовый проект на GitHub <a href=\"https://github.com/hiyouga/LLaMA-Factory\">LLaMA-Factory</a>.</p>\n<p>Финальной статьёй года стал разбор <a href=\"https://habr.com/ru/articles/863232/\">вызова функций в Ollama</a>. <a href=\"https://github.com/open-webui/pipelines/pull/352\">Доработав</a> промежуточную библиотеку <a href=\"https://github.com/open-webui/pipelines\">Pipelines</a>, я понял гениальную идею предварительной обработки запросов и внёс изменения в проект для стабильной работы Ollama. Так как разработчики сосредоточили свои усилия на закрытом проекте OpenAI, то Ollama прошла слабо протестированной. Я же ставлю своей целью использование только открытых продуктов, чтобы иметь больше гибкости в дальнейшем.</p>\n<p>Дополнительно я хотел освоить Kubernest. Но для его запуска необходимо было пройти блокировку. Результатом стал <a href=\"https://github.com/HardAndHeavy/terrashine-docker\">форк проекта terrashine</a> и <a href=\"https://github.com/Isawan/terrashine/pull/429\">изучение Rust</a>, а также <a href=\"https://habr.com/ru/articles/857474/\">статья на Хабре</a> о том, как обходить блокировки изнутри и снаружи.</p>\n<p>В ходе всего года я не изменял своему правилу <a href=\"https://habr.com/ru/articles/508672/\">фиксации мыслей в цеттелькастн</a>, что дало возможность написать пять статей. Моя база знаний значительно окрепла и расширилась. При этом я начинаю чувствую уверенность, что продолжая в том же духе смогу написать книгу.</p>\n<p>Приятным дополнением в завершении года были два проекта, которые мне добавили сын и жена, за что им огромное спасибо. Сын купил 3D-принтер, и я понял, как собирать g-code, находить и печатать любые модели. Жена добавила увлекательную идею, так что пришлось перепробовать несколько разных проектов на Python <a href=\"https://github.com/saleor/saleor\">saleor</a>, Ruby <a href=\"https://github.com/spree/spree\">spree</a> и JavaScript <a href=\"https://github.com/medusajs/medusa\">medusa</a>. После тщательного анализа судьба снова погрузила меня в мир JavaScript. Проект мощный, интересный, так что планов стало ещё больше, и все они очень интересные. 2025 год должен быть захватывающим!</p>","frontmatter":{"title":"Итоги 2024","date":"07 января 2025","description":"2024 год начался для меня с замечательного подарка от Деда Мороза — видеокарты AMD Radeon RX 7900 XTX."}}},"pageContext":{"slug":"/facts_2024/","previous":{"fields":{"slug":"/dialogflow_cx/"},"frontmatter":{"title":"Dialogflow CX"}},"next":{"fields":{"slug":"/plans_2025/"},"frontmatter":{"title":"Планы 2025"}}}},"staticQueryHashes":["1768383048","3000541721","500175580"],"slicesMap":{}}